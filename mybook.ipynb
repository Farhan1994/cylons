{"cells":[{"cell_type":"code","source":["# THis is just a COMPUTE node!\n# this has a LOCAL filesystem -> which is just a reference point\n# all my data -> DataLake!\n# LOAD my DataLake into Databricks!\n#   -> MOUNTING "],"metadata":{},"outputs":[],"execution_count":1},{"cell_type":"code","source":["# source is datalake, mount-> local name for this datalake to treat it like a\n# local file system\n# wasbs; http, ftp, and other protocols, wasb is the default communication \n# protocol for apache spark, wasbs -> secure for for it!\n#dbutils.fs.mount(source='wasbs://containername@storageaccount', mount_point, extra_configs)\n# giraffeisagovernmentconspiracy\n# pikapikapikachu.blob.core.windows.net\n\n# /mnt -> mnt is a folder which holds all the disk available to spark cluster\n\n# extra configs: this is the name of reference that developer should use instead of \n# actual path or secret or connection string\n# key: value\n# key-> file system to actually access lake \n# value-> secret to access the file system\n\n# key: fs.azure.sas.container\n# value: secret\n\n# previous syntax-> storage account (fs.azure.sas.)\n# this syntax -> datalakes (fs.azure.account.key.)\n\ndbutils.fs.mount(source='wasbs://giraffeisagovernmentconspiracy@pikapikapikachu.blob.core.windows.net', mount_point='/mnt/lake', extra_configs= {\"fs.azure.account.key.pikapikapikachu.blob.core.windows.net\":dbutils.secrets.get(scope='melody',key='mysecret')})"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"><span class=\"ansired\">Out[</span><span class=\"ansired\">6</span><span class=\"ansired\">]: </span>True</div>"]}}],"execution_count":2},{"cell_type":"code","source":["# because this file is locally present, i can access via sparkcontext!\n\ndf = spark.read.csv('/mnt/lake/cylons.csv', header=True)\n"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":3},{"cell_type":"code","source":["df.show()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+------+-------+---+\n Fname|  Lname|age|\n+------+-------+---+\n Peter| Parker| 99|\nDonald|   Duck| 22|\n Peter|Griffin| 80|\n+------+-------+---+\n\n</div>"]}}],"execution_count":4},{"cell_type":"code","source":["df.head()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"><span class=\"ansired\">Out[</span><span class=\"ansired\">10</span><span class=\"ansired\">]: </span>Row(Fname=&apos;Peter&apos;, Lname=&apos;Parker&apos;, age=&apos;99&apos;)</div>"]}}],"execution_count":5},{"cell_type":"code","source":["\n# all data, and processing is happening in RAM\n# if you data was 20GB, and ram is just 2 GB-> how do i even load?\n# data size => every data point is stored at least thrice \n#    - BigQuery, BigTable, DataBricks, CosmosDB, DataLakes, S3\n# planning for RAM-> at least THRICE than the data you need to process \n"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":6},{"cell_type":"code","source":["# we can use SQL statements without any external factor\nmydata = df.select('Fname','age')\nmydata.show()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+------+---+\n Fname|age|\n+------+---+\n Peter| 99|\nDonald| 22|\n Peter| 80|\n+------+---+\n\n</div>"]}}],"execution_count":7},{"cell_type":"code","source":["renameddf = df.withColumnRenamed('Fname','name')\nrenameddf.show()\n"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+------+-------+---+\n  name|  Lname|age|\n+------+-------+---+\n Peter| Parker| 99|\nDonald|   Duck| 22|\n Peter|Griffin| 80|\n+------+-------+---+\n\n</div>"]}}],"execution_count":8},{"cell_type":"code","source":["from pyspark import Row\n# ROW => represents logic to create a SINGLE ROW in RDD \n# dummy records or read from external source like file or db!\nrecords= [('Pikachu',55),('Yokozuna',20),('Scrooge',25),('gangadhar',40)]\nrdd = sc.parallelize(records) # RDD's memory allocation request \nmyData = rdd.map(lambda record: Row(name=record[0], age=record[1])) \n# a logic to create a ROW-> lambda function to logic"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":9},{"cell_type":"code","source":["myDF = sqlContext.createDataFrame(myData)\nmyDF.show() \n# SQL -> order of column NEVER mattered in the first place!\n# EVERY column is a new file by itself!!! \n# ORDER of your columns will not matter! "],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+---+---------+\nage|     name|\n+---+---------+\n 55|  Pikachu|\n 20| Yokozuna|\n 25|  Scrooge|\n 40|gangadhar|\n+---+---------+\n\n</div>"]}}],"execution_count":10},{"cell_type":"code","source":["# load csv \n#alldata = sqlContext.load(source='com.databricks.spark.csv',path='/mnt/lake/cylons.csv', header=True, inferSchema=True)\n\ndf = sqlContext.read.format('com.databricks.spark.csv').options(header='true', inferschema='true').load('/mnt/lake/data.csv')\ndf.printSchema()\n\n# 4:15 please resume! "],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">root\n-- id: integer (nullable = true)\n-- diagnosis: string (nullable = true)\n-- radius_mean: double (nullable = true)\n-- texture_mean: double (nullable = true)\n-- perimeter_mean: double (nullable = true)\n-- area_mean: double (nullable = true)\n-- smoothness_mean: double (nullable = true)\n-- compactness_mean: double (nullable = true)\n-- concavity_mean: double (nullable = true)\n-- concave points_mean: double (nullable = true)\n-- symmetry_mean: double (nullable = true)\n-- fractal_dimension_mean: double (nullable = true)\n-- radius_se: double (nullable = true)\n-- texture_se: double (nullable = true)\n-- perimeter_se: double (nullable = true)\n-- area_se: double (nullable = true)\n-- smoothness_se: double (nullable = true)\n-- compactness_se: double (nullable = true)\n-- concavity_se: double (nullable = true)\n-- concave points_se: double (nullable = true)\n-- symmetry_se: double (nullable = true)\n-- fractal_dimension_se: double (nullable = true)\n-- radius_worst: double (nullable = true)\n-- texture_worst: double (nullable = true)\n-- perimeter_worst: double (nullable = true)\n-- area_worst: double (nullable = true)\n-- smoothness_worst: double (nullable = true)\n-- compactness_worst: double (nullable = true)\n-- concavity_worst: double (nullable = true)\n-- concave points_worst: double (nullable = true)\n-- symmetry_worst: double (nullable = true)\n-- fractal_dimension_worst: double (nullable = true)\n-- _c32: string (nullable = true)\n\n</div>"]}}],"execution_count":11},{"cell_type":"code","source":["stats = df.describe('smoothness_mean')\nstats.show()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+-------+--------------------+\nsummary|     smoothness_mean|\n+-------+--------------------+\n  count|                 569|\n   mean|   0.096360281195079|\n stddev|0.014064128137673616|\n    min|             0.05263|\n    max|              0.1634|\n+-------+--------------------+\n\n</div>"]}}],"execution_count":12},{"cell_type":"code","source":["x = df.select('smoothness_mean').subtract(df.select('smoothness_worst'))\n# FORMER - LATTER \n# NUMPY , instead of nUMPY-> sql INSTEAD\nx.head(5)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"><span class=\"ansired\">Out[</span><span class=\"ansired\">32</span><span class=\"ansired\">]: </span>[Row(smoothness_mean=0.09754),\n Row(smoothness_mean=0.08182),\n Row(smoothness_mean=0.09592),\n Row(smoothness_mean=0.08999),\n Row(smoothness_mean=0.08597)]</div>"]}}],"execution_count":13},{"cell_type":"code","source":["x = df.crosstab('radius_mean','diagnosis')\n# using crosstab, you can also check FREQ Distribution\nx.show()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+---------------------+---+---+\nradius_mean_diagnosis|  B|  M|\n+---------------------+---+---+\n                11.89|  3|  0|\n                19.27|  0|  1|\n                13.34|  1|  0|\n                14.25|  0|  2|\n                11.22|  2|  0|\n                13.59|  2|  0|\n                20.48|  0|  1|\n                9.436|  1|  0|\n                12.46|  2|  1|\n                13.62|  1|  0|\n                25.73|  0|  1|\n                14.29|  1|  0|\n                17.85|  1|  0|\n                15.61|  0|  1|\n                12.32|  1|  0|\n                 10.2|  1|  0|\n                 15.3|  0|  1|\n                12.65|  1|  0|\n                12.95|  1|  0|\n                9.295|  1|  0|\n+---------------------+---+---+\nonly showing top 20 rows\n\n</div>"]}}],"execution_count":14},{"cell_type":"code","source":["df.dropna().count() # drop NULL values "],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"><span class=\"ansired\">Out[</span><span class=\"ansired\">35</span><span class=\"ansired\">]: </span>0</div>"]}}],"execution_count":15},{"cell_type":"code","source":["# GENERATE null values to handle in next block\nrecords= [(None,55),('Yokozuna',20),('Scrooge',25),('gangadhar',40)]\nrdd = sc.parallelize(records) # RDD's memory allocation request \nmyData = rdd.map(lambda record: Row(name=record[0], age=record[1])) \nmyDF = sqlContext.createDataFrame(myData)\nmyDF.show()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+---+---------+\nage|     name|\n+---+---------+\n 55|     null|\n 20| Yokozuna|\n 25|  Scrooge|\n 40|gangadhar|\n+---+---------+\n\n</div>"]}}],"execution_count":16},{"cell_type":"code","source":["df_null_replaced = myDF.fillna('No Name')\ndf_null_replaced.show()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+---+---------+\nage|     name|\n+---+---------+\n 55|  No Name|\n 20| Yokozuna|\n 25|  Scrooge|\n 40|gangadhar|\n+---+---------+\n\n</div>"]}}],"execution_count":17},{"cell_type":"code","source":["filteredDF = df.filter(df.smoothness_mean>0.1)\nprint(filteredDF.count())"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">216\n</div>"]}}],"execution_count":18},{"cell_type":"code","source":["df.groupby('diagnosis').count().show()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+---------+-----+\ndiagnosis|count|\n+---------+-----+\n        B|  357|\n        M|  212|\n+---------+-----+\n\n</div>"]}}],"execution_count":19},{"cell_type":"code","source":["df.groupby('diagnosis').agg({'radius_mean':'mean'}).show()\n# Malignent cells have to be larger then benign cancer cells !\n"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+---------+-----------------+\ndiagnosis| avg(radius_mean)|\n+---------+-----------------+\n        B|12.14652380952381|\n        M|17.46283018867925|\n+---------+-----------------+\n\n</div>"]}}],"execution_count":20},{"cell_type":"code","source":["# Python -> SAMPLE can be used to divide data into multiple dataframes\nt1 = df.sample(False,0.2,42) # 20% data, random_state=43\nt2 = df.sample(False,0.2,43) # 20% data, random_state=43\nt3 = df.sample(False,0.2,44)\n# we ensured that same shuffling doesn't result in same dataset! \n# there was some data overlapping! \nprint(t1.count())\nprint(t2.count())\nprint(t3.count())\n"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">121\n100\n115\n</div>"]}}],"execution_count":21},{"cell_type":"code","source":["# drop columns ->ONLY after Exploratory Data Analysis\nprint(df.columns)\ncols = df.drop('id').columns # it was a list over here\n# cols = df.drop('id') # this would be a DataFrame \nprint(cols)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">[&apos;id&apos;, &apos;diagnosis&apos;, &apos;radius_mean&apos;, &apos;texture_mean&apos;, &apos;perimeter_mean&apos;, &apos;area_mean&apos;, &apos;smoothness_mean&apos;, &apos;compactness_mean&apos;, &apos;concavity_mean&apos;, &apos;concave points_mean&apos;, &apos;symmetry_mean&apos;, &apos;fractal_dimension_mean&apos;, &apos;radius_se&apos;, &apos;texture_se&apos;, &apos;perimeter_se&apos;, &apos;area_se&apos;, &apos;smoothness_se&apos;, &apos;compactness_se&apos;, &apos;concavity_se&apos;, &apos;concave points_se&apos;, &apos;symmetry_se&apos;, &apos;fractal_dimension_se&apos;, &apos;radius_worst&apos;, &apos;texture_worst&apos;, &apos;perimeter_worst&apos;, &apos;area_worst&apos;, &apos;smoothness_worst&apos;, &apos;compactness_worst&apos;, &apos;concavity_worst&apos;, &apos;concave points_worst&apos;, &apos;symmetry_worst&apos;, &apos;fractal_dimension_worst&apos;, &apos;_c32&apos;]\n[&apos;diagnosis&apos;, &apos;radius_mean&apos;, &apos;texture_mean&apos;, &apos;perimeter_mean&apos;, &apos;area_mean&apos;, &apos;smoothness_mean&apos;, &apos;compactness_mean&apos;, &apos;concavity_mean&apos;, &apos;concave points_mean&apos;, &apos;symmetry_mean&apos;, &apos;fractal_dimension_mean&apos;, &apos;radius_se&apos;, &apos;texture_se&apos;, &apos;perimeter_se&apos;, &apos;area_se&apos;, &apos;smoothness_se&apos;, &apos;compactness_se&apos;, &apos;concavity_se&apos;, &apos;concave points_se&apos;, &apos;symmetry_se&apos;, &apos;fractal_dimension_se&apos;, &apos;radius_worst&apos;, &apos;texture_worst&apos;, &apos;perimeter_worst&apos;, &apos;area_worst&apos;, &apos;smoothness_worst&apos;, &apos;compactness_worst&apos;, &apos;concavity_worst&apos;, &apos;concave points_worst&apos;, &apos;symmetry_worst&apos;, &apos;fractal_dimension_worst&apos;, &apos;_c32&apos;]\n</div>"]}}],"execution_count":22},{"cell_type":"code","source":["df.registerTempTable('bc_table') # i can write QUERIES on the df, \n# as if it were a SQL \nx = sqlContext.sql('select radius_mean from bc_table')\nx.show()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+-----------+\nradius_mean|\n+-----------+\n      17.99|\n      20.57|\n      19.69|\n      11.42|\n      20.29|\n      12.45|\n      18.25|\n      13.71|\n       13.0|\n      12.46|\n      16.02|\n      15.78|\n      19.17|\n      15.85|\n      13.73|\n      14.54|\n      14.68|\n      16.13|\n      19.81|\n      13.54|\n+-----------+\nonly showing top 20 rows\n\n</div>"]}}],"execution_count":23},{"cell_type":"code","source":["#                Python       PySpark\n# a=1              a=1          True\n# b=2              b=2          True\n# c=a+b            c=3          True\n# print(c)         3            starts solving-> gives you result"],"metadata":{},"outputs":[],"execution_count":24},{"cell_type":"code","source":["print(df.columns)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">[&apos;id&apos;, &apos;diagnosis&apos;, &apos;radius_mean&apos;, &apos;texture_mean&apos;, &apos;perimeter_mean&apos;, &apos;area_mean&apos;, &apos;smoothness_mean&apos;, &apos;compactness_mean&apos;, &apos;concavity_mean&apos;, &apos;concave points_mean&apos;, &apos;symmetry_mean&apos;, &apos;fractal_dimension_mean&apos;, &apos;radius_se&apos;, &apos;texture_se&apos;, &apos;perimeter_se&apos;, &apos;area_se&apos;, &apos;smoothness_se&apos;, &apos;compactness_se&apos;, &apos;concavity_se&apos;, &apos;concave points_se&apos;, &apos;symmetry_se&apos;, &apos;fractal_dimension_se&apos;, &apos;radius_worst&apos;, &apos;texture_worst&apos;, &apos;perimeter_worst&apos;, &apos;area_worst&apos;, &apos;smoothness_worst&apos;, &apos;compactness_worst&apos;, &apos;concavity_worst&apos;, &apos;concave points_worst&apos;, &apos;symmetry_worst&apos;, &apos;fractal_dimension_worst&apos;, &apos;_c32&apos;]\n</div>"]}}],"execution_count":25},{"cell_type":"code","source":["spark"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["\n            <div>\n                <p><b>SparkSession - hive</b></p>\n                \n        <div>\n            <p><b>SparkContext</b></p>\n\n            <p><a href=\"http://10.139.64.4:44111\">Spark UI</a></p>\n\n            <dl>\n              <dt>Version</dt>\n                <dd><code>v2.4.3</code></dd>\n              <dt>Master</dt>\n                <dd><code>spark://10.139.64.4:7077</code></dd>\n              <dt>AppName</dt>\n                <dd><code>Databricks Shell</code></dd>\n            </dl>\n        </div>\n        \n            </div>\n        "]}}],"execution_count":26},{"cell_type":"code","source":["sc"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["\n        <div>\n            <p><b>SparkContext</b></p>\n\n            <p><a href=\"http://10.139.64.4:44111\">Spark UI</a></p>\n\n            <dl>\n              <dt>Version</dt>\n                <dd><code>v2.4.3</code></dd>\n              <dt>Master</dt>\n                <dd><code>spark://10.139.64.4:7077</code></dd>\n              <dt>AppName</dt>\n                <dd><code>Databricks Shell</code></dd>\n            </dl>\n        </div>\n        "]}}],"execution_count":27},{"cell_type":"code","source":[""],"metadata":{},"outputs":[],"execution_count":28}],"metadata":{"name":"mybook","notebookId":3114049443956910},"nbformat":4,"nbformat_minor":0}
