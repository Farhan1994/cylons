{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "08 SentimentAnalysis.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNVhU/zI7ece36O1HA/FJpH",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/a-forty-two/cylons/blob/master/08_SentimentAnalysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TPVe_x8nMtPO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# NLTK, Spacy, Textacy -> MANIPULATE TEXT -> NLP Pipelines \n",
        "\n",
        "# ML -> NUMBERS only \n",
        "# Approaches to CONVERT text into NUMBERS or VECTORS or TENSORS \n",
        "# y = mx + c where x is an language statement \n",
        "\n",
        "# MANIPULATED standards -> CONVINIENCE \n",
        "\n",
        "# SPECIAL SYMBOLS INSIDE OUR TEXT so that code could be used to manipulate them \n",
        "# WE AS DEVELOPERS OR NLP Engineers manipulate text and add these symbols\n",
        "# <PAD>   0   -> Neural networks are HARDCODED-> input-size cannot be change once NN is built!\n",
        "# padding helps chopping/padding different length sentences into same size\n",
        "# I am good;   Bye.   ->    [I, am, good] ; [Bye, <PAD>, <PAD>]\n",
        "# y = mx+c ;   y = w1*I + w2*am + w3*good + bias ;   y = w1*bye + w2 * <PAD> + w3 * <PAD>\n",
        "# y = w1*100 + w2*22 + w3*55 + 102;   y = w1*42 + w2* 0 + w3* 0  \n",
        "# <START> 1   -> indicates beginning of a sentence or phrase \n",
        "# example; if text was Hello World! -> 42 50 \n",
        "# Processed statement: <START> Hello World! -> 1 42 50\n",
        "# this way when multiple sentences were present, we could mark beginning of each sentence/phrase\n",
        "\n",
        "# <PAD> 0          -> 0, any weight multiplied to <PAD> will become 0! \n",
        "# <START>  1       -> Indicates beginning of sentence/phrase \n",
        "# <UNK>  2         -> your encountered a word outside dictionary \n",
        "# <UNUSED> 3       -> SPECIAL symbol that you could give special meaning to \n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rOl3RkrXSQiL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "95b88d36-0ba4-456b-c1b6-70ecfb1aa53e"
      },
      "source": [
        "# IMDB -> has a lot of movie reviews \n",
        "# POS, NEG -> our output for a Review \n",
        "# Sentiment = weights * review + bias \n",
        "\n",
        "%tensorflow_version 1.x\n",
        "import tensorflow as tf\n",
        "print(tf.__version__)\n",
        "from tensorflow import keras\n",
        "import numpy as np"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.15.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cDbkhmqpUjZS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "e22c6016-b3d8-49dc-ccfa-762ccc7f2f49"
      },
      "source": [
        "\n",
        "# DICTIONARIES are infinite! OXFORD, CAMBRIDGE, QUEEN's, GEORGE's, millions of words!\n",
        "# constantly increasing!\n",
        "# WE HAVE TO LIMIT OUR DICTIONARY TO A FINITE SIZE! \n",
        " # assuming our entire english consists of only 10,000 words! \n",
        "# REST of the words -> <UNKNOWN>!!!!\n",
        "imdb = keras.datasets.imdb \n",
        "HP_dictionary_size = 10000\n",
        "(xtrain, ytrain), (xtest, ytest) = imdb.load_data(num_words=HP_dictionary_size)\n",
        "\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb.npz\n",
            "17465344/17464789 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vWIWicVZWDRv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        },
        "outputId": "d2e1fdc3-03aa-416d-a695-97d3c9aa5476"
      },
      "source": [
        "print(xtrain[2])"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1, 14, 47, 8, 30, 31, 7, 4, 249, 108, 7, 4, 5974, 54, 61, 369, 13, 71, 149, 14, 22, 112, 4, 2401, 311, 12, 16, 3711, 33, 75, 43, 1829, 296, 4, 86, 320, 35, 534, 19, 263, 4821, 1301, 4, 1873, 33, 89, 78, 12, 66, 16, 4, 360, 7, 4, 58, 316, 334, 11, 4, 1716, 43, 645, 662, 8, 257, 85, 1200, 42, 1228, 2578, 83, 68, 3912, 15, 36, 165, 1539, 278, 36, 69, 2, 780, 8, 106, 14, 6905, 1338, 18, 6, 22, 12, 215, 28, 610, 40, 6, 87, 326, 23, 2300, 21, 23, 22, 12, 272, 40, 57, 31, 11, 4, 22, 47, 6, 2307, 51, 9, 170, 23, 595, 116, 595, 1352, 13, 191, 79, 638, 89, 2, 14, 9, 8, 106, 607, 624, 35, 534, 6, 227, 7, 129, 113]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "enE6vHS7WMTN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "dbb7b7a9-fee4-4b50-ebcf-06d25b2f3014"
      },
      "source": [
        "ytrain[:5]\n",
        "# there are 2 outputs -> 0 or 1"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 0, 0, 1, 0])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EUgbUCYnYJ3j",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "52b99d15-ee66-4ce8-b582-d41b1d70eb93"
      },
      "source": [
        "word_index = imdb.get_word_index()   # DICTIONARY HAS TO BE PROVIDED BY DATASET!\n",
        "# WHOEVER BUILDS DATASET HAS TO BUILD DICTIONARY AS PER THEIR ENCODING \n",
        "word_index['bye']\n",
        "# PRECISELY OPPOSITE of what we need! This can help us with ENCODING, not decoding\n",
        "# ENCODING is already done! \n",
        "# how do we decode? -> REVERSE THE DICTIONARY!!\n",
        "# Pass it word -> GIVES you a number!\n",
        "# Our reverse dict -> PASS a number, and get word back "
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5455"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "48Q8ER0RY2VC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}